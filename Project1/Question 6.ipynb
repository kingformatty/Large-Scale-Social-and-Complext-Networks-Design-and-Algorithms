{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import random\n",
    "random.seed(42)\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories = ['comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware', 'rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey']\n",
    "train_dataset = datasets.fetch_20newsgroups(subset = 'train', categories = categories, shuffle = True, random_state = None)\n",
    "test_dataset = datasets.fetch_20newsgroups(subset = 'test', categories = categories, shuffle = True, random_state = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of stop_words in sklearn text:318\n"
     ]
    }
   ],
   "source": [
    "from nltk import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#Define Stopwords, here we use stopwords in text package\n",
    "stop_words=text.ENGLISH_STOP_WORDS\n",
    "print(\"number of stop_words in sklearn text:%s\" % len(stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Lemmatization\n",
    "lemmatizer=WordNetLemmatizer()\n",
    "#Define lemmatizer pos_tag to deal with adj, verb, noun and adv separately\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "#Preprocessing: exclude some symbols and numbers in each sentence\n",
    "exclude_sign=\"~#$%^&*(){}[]<>|+=1234567890\"\n",
    "replace_sign=\"@,.?!-;\"\n",
    "def preprocessing(data):\n",
    "    processed_sentence=[]\n",
    "    for i in range(len(data)):\n",
    "        sentence=data[i]\n",
    "        for c in exclude_sign:\n",
    "            sentence=sentence.replace(c,\"\")\n",
    "        for c in replace_sign:\n",
    "            sentence=sentence.replace(c,\" \")\n",
    "        processed_token=[lemmatizer.lemmatize(w,get_wordnet_pos(w)) for w in nltk.word_tokenize(sentence)]\n",
    "        processed_sentence.append(\" \".join(processed_token))\n",
    "    return processed_sentence\n",
    "#Training\n",
    "\n",
    "vectorizer=CountVectorizer(stop_words='english',min_df=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#implement new dataset\n",
    "categories_computer=['comp.graphics', 'comp.os.ms-windows.misc', 'comp.sys.ibm.pc.hardware', 'comp.sys.mac.hardware']\n",
    "categories_rec=['rec.autos', 'rec.motorcycles', 'rec.sport.baseball', 'rec.sport.hockey']\n",
    "computer_train=datasets.fetch_20newsgroups(subset = 'train', categories = categories_computer, shuffle = True, random_state = None).data\n",
    "computer_test=datasets.fetch_20newsgroups(subset = 'test', categories = categories_computer, shuffle = True, random_state = None).data\n",
    "recreation_train=datasets.fetch_20newsgroups(subset = 'train', categories = categories_rec, shuffle = True, random_state = None).data\n",
    "recreation_test=datasets.fetch_20newsgroups(subset = 'test', categories = categories_rec, shuffle = True, random_state = None).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7882,)\n"
     ]
    }
   ],
   "source": [
    "#implement new dataset cont'd: combine train and test together and save as X_overall\n",
    "X_train=computer_train+recreation_train\n",
    "X_test=computer_test+recreation_test\n",
    "X_overall=X_train+X_test\n",
    "Y_train=[1]*len(computer_train)+[0]*len(recreation_train)\n",
    "Y_test=[1]*len(computer_test)+[0]*len(recreation_test)\n",
    "print(np.shape(X_overall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Lemmatization\n",
    "processed_train_data=preprocessing(X_overall)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Vectorization\n",
    "data_vec=vectorizer.fit_transform(processed_train_data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TdIdf\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "TdT=TfidfTransformer()\n",
    "data_vec_ti=TdT.fit_transform(data_vec)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7882, 50)\n"
     ]
    }
   ],
   "source": [
    "#LSI\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "transformer=TruncatedSVD(n_components=50)\n",
    "data_svd=transformer.fit_transform(data_vec_ti)\n",
    "print(np.shape(data_svd))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7882, 50)\n",
      "<type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#nmf\n",
    "from sklearn.decomposition import NMF\n",
    "nmf=NMF(n_components=50)\n",
    "data_nmf=nmf.fit_transform(data_vec_ti)\n",
    "print(np.shape(data_nmf))\n",
    "print(type(data_svd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.matrix'>\n",
      "(7882, 21423)\n",
      "LSI error:\n",
      "83.3838947603005\n",
      "NMF error:\n",
      "83.68714377746208\n"
     ]
    }
   ],
   "source": [
    "#error\n",
    "xhat=np.dot(data_svd,transformer.components_)\n",
    "\n",
    "data_mat=data_vec_ti.todense()\n",
    "data_ar=data_mat.getA()\n",
    "\n",
    "dif=xhat-data_mat\n",
    "error=0\n",
    "print(type(dif))\n",
    "print(np.shape(dif))\n",
    "error_lsi=np.sqrt(np.trace(np.dot(dif.T,dif)))\n",
    "print('LSI error:')\n",
    "print(error_lsi)\n",
    "\n",
    "nmf_div=nmf.reconstruction_err_\n",
    "print('NMF error:')\n",
    "print(nmf_div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4732, 50)\n",
      "(3150, 50)\n"
     ]
    }
   ],
   "source": [
    "X_train_tf=data_svd[0:len(X_train)]\n",
    "print(np.shape(X_train_tf))\n",
    "X_test_tf=data_svd[len(X_train):]\n",
    "print(np.shape(X_test_tf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questioni 6\n",
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "\n",
    "def naive_Gaussian_model(X_train, Y_train, X_test, Y_test):\n",
    "    Gaussian_classifier=GaussianNB()\n",
    "    Gaussian_classifier.fit(X_train, Y_train)\n",
    "    predict_target=Gaussian_classifier.predict(X_test)\n",
    "    #print('predict_score from decision function is')\n",
    "    #print(predict_score)\n",
    "    #print('predict_score_1 from predict_proba is ')\n",
    "    predict_score_1=Gaussian_classifier.predict_proba(X_test)  \n",
    "    FPR, TPR, threshold=metrics.roc_curve(Y_test,predict_score_1[:,1])\n",
    "    return (predict_target, predict_score_1, FPR, TPR, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Evalutation\n",
    "\n",
    "#Model Metrics\n",
    "def evaluation(Y_predict, Y_test, FPR, TPR):\n",
    "    confusion_matrix=metrics.confusion_matrix(Y_test,Y_predict)\n",
    "    accuracy=metrics.accuracy_score(Y_test, Y_predict)\n",
    "    recall=metrics.recall_score(Y_test, Y_predict, average='binary')\n",
    "    precision=metrics.precision_score(Y_test, Y_predict, average='binary')\n",
    "    f1_score=metrics.f1_score(Y_test, Y_predict, average='binary')\n",
    "    roc=metrics.auc(FPR, TPR)\n",
    "    plt.plot(FPR,TPR, lw=2, label='area under vurve= %0.4f' % roc)\n",
    "    plt.show()\n",
    "    print('Confusion matrix is: ')\n",
    "    print(confusion_matrix)\n",
    "    print('accuracy: %f' % accuracy)\n",
    "    print('recall: %f' % recall)\n",
    "    print('precision: %f' % precision)\n",
    "    print('f1_score: %f' % f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUoOMuyQ1yLhLUoOMuyQ16P8BwHqUK7MlqdMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x121288f90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix is: \n",
      "[[1487  103]\n",
      " [ 160 1400]]\n",
      "accuracy: 0.916508\n",
      "recall: 0.897436\n",
      "precision: 0.931470\n",
      "f1_score: 0.914136\n"
     ]
    }
   ],
   "source": [
    "predict_target, predict_score, FPR, TPR, threshold= naive_Gaussian_model(X_train_tf, Y_train, X_test_tf, Y_test)\n",
    "evaluation(predict_target, Y_test, FPR, TPR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
